{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NLP. Tarea 2: Minería de Texto Básica**.\n",
    "\n",
    "*Diego Moreno*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bolsas de Palabras, Bigramas y Emociones\n",
    "\n",
    "Importamos las librerías necesarias para la tarea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "#from keras.preprocessing.text import Tokenizer \n",
    "import nltk\n",
    "#import glob\n",
    "from nltk import FreqDist\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#from nltk.text import Text\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from nltk import ngrams\n",
    "#from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "#from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los datos Mex-A3t y preprocesamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(path_corpus, path_labels):\n",
    "    tr_txt = []\n",
    "    tr_y = []\n",
    "    \n",
    "    with open(path_corpus, 'r') as f_corpus, open(path_labels, 'r') as f_labels:\n",
    "        for twitt in f_corpus:\n",
    "            tr_txt += [twitt]\n",
    "        for label in f_labels:\n",
    "            tr_y += [label]\n",
    "    return tr_txt, tr_y\n",
    "\n",
    "def sort_freq_dict(fdict):\n",
    "    aux = [(fdict[key], key) for key in fdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_txt, tr_y = get_text_from_file('mex_train.txt', 'mex_train_labels.txt')\n",
    "tr_y = list(map(int, tr_y))\n",
    "val_txt, val_y = get_text_from_file('mex_val.txt', 'mex_val_labels.txt')\n",
    "val_y = list(map(int, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "corpus_words = []\n",
    "for doc in tr_txt:\n",
    "    corpus_words += tokenizer.tokenize(doc)\n",
    "\n",
    "fdist = nltk.FreqDist(corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = sort_freq_dict(fdist) \n",
    "V = v[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ind = dict()\n",
    "count = 0\n",
    "for _, word in V:\n",
    "    dict_ind[word] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Bolsas de Términos\n",
    "\n",
    "A continuación, coloco todos los constructores de las bolsas de términos; correponden a las bolsas solicitadas para los puntos 2.1, 2.2, 2.3, 2.4, 2.5 y 2.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bow_binary(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado binario.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=int)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_ind:\n",
    "                bow[doc_count, dict_ind[word]] = 1\n",
    "        doc_count += 1\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tf(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento. \n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=int)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_ind:\n",
    "                bow[doc_count, dict_ind[word]] = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tfidf(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento y penalizado por la frecuencia del término\n",
    "    en cada documento.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=float)\n",
    "    idf = np.zeros(len(V), dtype=float)\n",
    "    \n",
    "    # Parte de TF\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_ind:\n",
    "                bow[doc_count, dict_ind[word]] = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Parte de IDF\n",
    "    N = len(tr_txt)\n",
    "    for word in dict_ind:\n",
    "        df = sum(bow[:, dict_ind[word]] > 0)\n",
    "        if df == 0:\n",
    "            df = 1\n",
    "        idf[dict_ind[word]] = np.log(N) - np.log(df)\n",
    "        \n",
    "    bow *= idf\n",
    "    return bow\n",
    "\n",
    "def build_bow_binary_norm(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado binario.\n",
    "    Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_ind:\n",
    "                bow[doc_count, dict_ind[word]] = 1\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tf_norm(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento. Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_ind:\n",
    "                bow[doc_count, dict_ind[word]] = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tfidf_norm(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento y penalizado por la frecuencia del término\n",
    "    en cada documento. Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=float)\n",
    "    idf = np.zeros(len(V), dtype=float)\n",
    "    \n",
    "    # Parte de TF\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_ind:\n",
    "                bow[doc_count, dict_ind[word]] = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Parte de IDF\n",
    "    N = len(tr_txt)\n",
    "    for word in dict_ind:\n",
    "        df = sum(bow[:, dict_ind[word]] > 0)\n",
    "        if df == 0:\n",
    "            df = 1\n",
    "        idf[dict_ind[word]] = np.log(N) - np.log(df)\n",
    "        \n",
    "    bow *= idf\n",
    "    \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        bow[i] /= sum_w\n",
    "            \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de los modelos con SVM y reporte de clasificación:\n",
    "\n",
    "## 2.1 Esquema de pesado binario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_binary(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_binary(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasificación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C' : [.05, .12, .25, .5, 1, 2, 4]}\n",
    "\n",
    "svr = svm.LinearSVC(class_weight = 'balanced')\n",
    "grid = GridSearchCV(estimator = svr, param_grid = params, n_jobs = 8,\n",
    "                   scoring = 'f1_macro', cv = 5)\n",
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[331  66]\n",
      " [ 49 170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       397\n",
      "           1       0.72      0.78      0.75       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.80      0.81      0.80       616\n",
      "weighted avg       0.82      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación de un twitt agresivo tuvo un f1-score de **0.75** y el modelo en general un accuracy de **0.81**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Esquema de pesado por frecuencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tf(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[334  63]\n",
      " [ 50 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       397\n",
      "           1       0.73      0.77      0.75       219\n",
      "\n",
      "    accuracy                           0.82       616\n",
      "   macro avg       0.80      0.81      0.80       616\n",
      "weighted avg       0.82      0.82      0.82       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación de un twitt agresivo tuvo un f1-score de **0.75** y el modelo en general un accuracy de **0.82**. Mejorando así, por 0.01 el accuracy del binario.\n",
    "\n",
    "## 2.3 Esquema de pesado por frecuencia en documento y penalizando por frecuencia en todos los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tfidf(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tfidf(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[321  76]\n",
      " [ 77 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       397\n",
      "           1       0.65      0.65      0.65       219\n",
      "\n",
      "    accuracy                           0.75       616\n",
      "   macro avg       0.73      0.73      0.73       616\n",
      "weighted avg       0.75      0.75      0.75       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación de un twitt agresivo tuvo un f1-score de **0.65**, empeorando por un 0.1 a lo anterior obtenido, y el modelo en general un accuracy de **0.75**. Empeorando así, por 0.07 el accuracy anterior.\n",
    "\n",
    "## 2.4 Ahora realicemos lo anterior pero con una normalización L2, a continuación el esquema binario normalizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_binary_norm(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_binary_norm(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[323  74]\n",
      " [ 48 171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       397\n",
      "           1       0.70      0.78      0.74       219\n",
      "\n",
      "    accuracy                           0.80       616\n",
      "   macro avg       0.78      0.80      0.79       616\n",
      "weighted avg       0.81      0.80      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación de un twitt agresivo tuvo un f1-score de **0.74**, empeorando por un 0.01 a lo anterior obtenido no normalizando, y el modelo en general un accuracy de **0.80**. Empeorando así, por 0.01 el accuracy anterior de igual manera.\n",
    "\n",
    "## 2.5 Esquema de pesado por frecuencia normalizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf_norm(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tf_norm(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322  75]\n",
      " [ 50 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       397\n",
      "           1       0.69      0.77      0.73       219\n",
      "\n",
      "    accuracy                           0.80       616\n",
      "   macro avg       0.78      0.79      0.78       616\n",
      "weighted avg       0.80      0.80      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarmente, la clasificación de un twitt agresivo tuvo un f1-score de **0.73**, empeorando por un 0.02 a lo anterior obtenido no normalizando, y el modelo en general un accuracy de **0.80**. Empeorando así, por 0.02 el accuracy anterior al no normalizar.\n",
    "\n",
    "## 2.6 Esquema de pesado por TF-IDF normalizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tfidf_norm(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tfidf_norm(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[317  80]\n",
      " [ 49 170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83       397\n",
      "           1       0.68      0.78      0.72       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.79      0.78       616\n",
      "weighted avg       0.80      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso, la clasificación de un twitt agresivo tuvo un f1-score de **0.72**, mejorando a 0.65 de lo anterior obtenido no normalizando, y el modelo en general un accuracy de **0.79**. Mejorando también, por 0.04 el accuracy anterior al no normalizar.\n",
    "\n",
    "## 2.7 Comparación de resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesado  | F1-score | Accuracy\n",
      "_______/_\\________/_\\________\n",
      "Binary  |   0.75   |   0.81\n",
      "--------+----------+---------\n",
      "Binary  |   0.74   |   0.80\n",
      "normed  |          |\n",
      "--------+----------+---------\n",
      "TF      |   0.75   |   0.82\n",
      "--------+----------+---------\n",
      "TF      |   0.73   |   0.80\n",
      "normed  |          |\n",
      "--------+----------+---------\n",
      "TF-IDF  |   0.65   |   0.75\n",
      "--------+----------+---------\n",
      "TF-IDF  |   0.72   |   0.79\n",
      "normed  |          |\n"
     ]
    }
   ],
   "source": [
    "print('Pesado  | F1-score | Accuracy\\n_______/_\\________/_\\________')\n",
    "print('Binary  |   0.75   |   0.81\\n--------+----------+---------')\n",
    "print('Binary  |   0.74   |   0.80\\nnormed  |          |\\n--------+----------+---------')\n",
    "print('TF      |   0.75   |   0.82\\n--------+----------+---------')\n",
    "print('TF      |   0.73   |   0.80\\nnormed  |          |\\n--------+----------+---------')\n",
    "print('TF-IDF  |   0.65   |   0.75\\n--------+----------+---------')\n",
    "print('TF-IDF  |   0.72   |   0.79\\nnormed  |          |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos a grandes rasgos que la normalización solamente beneficia al pesado TF-IDF, y el método con mejor desempeño en general es el TF manteniéndose constante. Por lo tanto, en el siguiente punto, elegiremos al pesado TF.\n",
    "\n",
    "## 2.8 Evaluamos con más y menos términos para TF\n",
    "\n",
    "Menos términos (500):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = v[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ind = dict()\n",
    "count = 0\n",
    "for _, word in V:\n",
    "    dict_ind[word] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tf(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320  77]\n",
      " [ 55 164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       397\n",
      "           1       0.68      0.75      0.71       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.78      0.77       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más términos (10000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = v[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ind = dict()\n",
    "count = 0\n",
    "for _, word in V:\n",
    "    dict_ind[word] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tf(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[335  62]\n",
      " [ 50 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       397\n",
      "           1       0.73      0.77      0.75       219\n",
      "\n",
      "    accuracy                           0.82       616\n",
      "   macro avg       0.80      0.81      0.80       616\n",
      "weighted avg       0.82      0.82      0.82       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Términos | F1-score | Accuracy | True Pos | True Neg\n",
      "________/_\\________/_\\________/_\\________/_\\________\n",
      "500      |   0.71   |   0.79   |    320   |    164\n",
      "---------+----------+----------+----------+---------\n",
      "5000     |   0.75   |   0.82   |    334   |    169\n",
      "---------+----------+----------+----------+---------\n",
      "10000    |   0.75   |   0.82   |    335   |    169\n"
     ]
    }
   ],
   "source": [
    "print('Términos | F1-score | Accuracy | True Pos | True Neg\\n________/_\\________/_\\________/_\\________/_\\________')\n",
    "print('500      |   0.71   |   0.79   |    320   |    164\\n---------+----------+----------+----------+---------')\n",
    "print('5000     |   0.75   |   0.82   |    334   |    169\\n---------+----------+----------+----------+---------')\n",
    "print('10000    |   0.75   |   0.82   |    335   |    169')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que para pocos términos, la clasificación es basada en pocos twitts por lo que no logra clasificar de manera correcta el conjunto de validación, teniendo como f-score y accuracy 71 y 79 respectivamente. Para 5000 términos, el f-score base es de 75 y accuracy de 82. Sin embargo, para más términos (10000) estos scores no aumentan significativamente, empero, al observar los verdaderos positivos, con un entrenamiento de 10000 palabras solo se aumenta a 1 twitt clasificado de manera correcta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Concatenación con bolsa de bi-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los bigramas del texto\n",
    "bigrams_tr = []\n",
    "for tr in tr_txt:\n",
    "    bigram = ngrams(tokenizer.tokenize(tr), 2)\n",
    "    bigrams_tr += bigram\n",
    "\n",
    "# Validación\n",
    "# Obtenemos los bigramas del texto\n",
    "bigrams_val = []\n",
    "for tr in val_txt:\n",
    "    bigram = ngrams(tokenizer.tokenize(tr), 2)\n",
    "    bigrams_val += bigram\n",
    "\n",
    "# Primeros 1000\n",
    "v_bigr = sort_freq_dict(nltk.FreqDist(bigrams_tr)) \n",
    "V_bigr = v_bigr[:1000]\n",
    "\n",
    "# Directorio de índices\n",
    "dict_ind_bigr = dict()\n",
    "count = 0\n",
    "for _,bigr in V_bigr:\n",
    "    dict_ind_bigr[bigr] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bobg_binary_norm(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de bigramas con un método de pesado binario.\n",
    "    Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        bigram = ngrams(tokenizer.tokenize(tr), 2)\n",
    "        fdist_doc = nltk.FreqDist(bigram)\n",
    "        for bigr in fdist_doc:\n",
    "            if bigr in dict_ind:\n",
    "                bow[doc_count, dict_ind[bigr]] = 1\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bobg_tf_norm(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de bigramas con pesado TF.\n",
    "    Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        bigram = ngrams(tokenizer.tokenize(tr), 2)\n",
    "        fdist_doc = nltk.FreqDist(bigram)\n",
    "        for bigr in fdist_doc:\n",
    "            if bigr in dict_ind:\n",
    "                bow[doc_count, dict_ind[bigr]] = fdist_doc[bigr]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bobg_tfidf_norm(tr_txt, V, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de bigramas con un método de pesado TF-IDF. \n",
    "    Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(V)), dtype=float)\n",
    "    idf = np.zeros(len(V), dtype=float)\n",
    "    \n",
    "    # Parte de TF\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        bigram = ngrams(tokenizer.tokenize(tr), 2)\n",
    "        fdist_doc = nltk.FreqDist(bigram)\n",
    "        for bigr in fdist_doc:\n",
    "            if bigr in dict_ind:\n",
    "                bow[doc_count, dict_ind[bigr]] = fdist_doc[bigr]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Parte de IDF\n",
    "    N = len(tr_txt)\n",
    "    for bigr in dict_ind:\n",
    "        df = sum(bow[:, dict_ind[bigr]] > 0)\n",
    "        if df == 0:\n",
    "            df = 1\n",
    "        idf[dict_ind[bigr]] = np.log(N) - np.log(df)\n",
    "        \n",
    "    bow *= idf\n",
    "    \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "            \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de términos\n",
    "bow_tr = build_bow_tf(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tf(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de bigramas\n",
    "bow_tr_bi = build_bobg_tfidf_norm(tr_txt, V_bigr, dict_ind_bigr)\n",
    "bow_val_bi = build_bobg_tfidf_norm(val_txt, V_bigr, dict_ind_bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr = np.concatenate((bow_tr, bow_tr_bi), axis=1)\n",
    "bow_val = np.concatenate((bow_val, bow_val_bi), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332  65]\n",
      " [ 52 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       397\n",
      "           1       0.72      0.76      0.74       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.80      0.80       616\n",
      "weighted avg       0.81      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se intentó concatenar una bolsa de bigramas pesado con binario, TF y TF-IDF y normalizado L2, con el esquema de pesado TF para el texto normal. Sin embargo, no se encontró una mejoría ni en f1-score ni en accuracy, puesto que ahora se obtiene 0.74 y 0.81 respectivamente, cuando antes se contaba con un 0.75 y 0.82 sin los bigramas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 Bolsa de emociones.\n",
    "\n",
    "La estrategia para dicha bolsa será para cada twitt, revisar cada palabra dicha en él en las palabras de emolex y ver el sentimiento de la palabra para así, contemplarlo en la columna correcta. La bolsa ahora contendrá 8 columnas correspondientes a las emociones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(path_corpus):\n",
    "    tr_txt = []\n",
    "    tr_y = []\n",
    "    \n",
    "    with open(path_corpus, 'r') as f_corpus:\n",
    "        for word in f_corpus:\n",
    "            word = word.split()\n",
    "            if len(word) < 5:\n",
    "                tr_txt += [word[1]]\n",
    "                tr_y += [word[2]]\n",
    "            \n",
    "    return tr_txt, tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex, emolex_y = get_text_from_file('Spanish-es-NRC-Emotion-Intensity-Lexicon-v1.txt')\n",
    "emolex = emolex[1:]\n",
    "emolex_y = emolex_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_dict = {}\n",
    "for i in range(len(emolex)):\n",
    "    word = emolex[i]\n",
    "    emolex_dict[word] = emolex_y[i]\n",
    "    \n",
    "emolex_dict_ind = {}\n",
    "count = 0\n",
    "for word in set(emolex_y):\n",
    "    emolex_dict_ind[word] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bow_binary_emolex(tr_txt, emo_dict, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado binario.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=int)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = 1\n",
    "        doc_count += 1\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tf_emolex(tr_txt, emo_dict, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento. \n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=int)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tfidf_emolex(tr_txt, emo_dict, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento y penalizado por la frecuencia del término\n",
    "    en cada documento.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(emo_dict)), dtype=float)\n",
    "    idf = np.zeros(len(emo_dict), dtype=float)\n",
    "    \n",
    "    # Parte de TF\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]]  = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Parte de IDF\n",
    "    N = len(tr_txt)\n",
    "    for word in emo_dict:\n",
    "        emo = emo_dict[word]\n",
    "        df = sum(bow[:, dict_ind[emo]] > 0)\n",
    "        if df == 0:\n",
    "            df = 1\n",
    "        idf[dict_ind[emo]] = np.log(N) - np.log(df)\n",
    "        \n",
    "    bow *= idf\n",
    "    return bow\n",
    "\n",
    "def build_bow_binary_norm_emolex(tr_txt, emo_dict, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado binario.\n",
    "    Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = 1\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tf_norm_emolex(tr_txt, emo_dict, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento. Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tfidf_norm_emolex(tr_txt, emo_dict, dict_ind):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento y penalizado por la frecuencia del término\n",
    "    en cada documento. Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(emo_dict)), dtype=float)\n",
    "    idf = np.zeros(len(emo_dict), dtype=float)\n",
    "    \n",
    "    # Parte de TF\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]]  = fdist_doc[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Parte de IDF\n",
    "    N = len(tr_txt)\n",
    "    for word in emo_dict:\n",
    "        emo = emo_dict[word]\n",
    "        df = sum(bow[:, dict_ind[emo]] > 0)\n",
    "        if df == 0:\n",
    "            df = 1\n",
    "        idf[dict_ind[emo]] = np.log(N) - np.log(df)\n",
    "        \n",
    "    bow *= idf\n",
    "    \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "            \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 Evaluamos las bolsas de emociones y comparamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emolex con binario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_binary_emolex(tr_txt, emolex_dict, emolex_dict_ind)\n",
    "bow_val = build_bow_binary_emolex(val_txt, emolex_dict, emolex_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183 214]\n",
      " [ 83 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.46      0.55       397\n",
      "           1       0.39      0.62      0.48       219\n",
      "\n",
      "    accuracy                           0.52       616\n",
      "   macro avg       0.54      0.54      0.52       616\n",
      "weighted avg       0.58      0.52      0.53       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emolex con TF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf_emolex(tr_txt, emolex_dict, emolex_dict_ind)\n",
    "bow_val = build_bow_tf_emolex(val_txt, emolex_dict, emolex_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183 214]\n",
      " [ 85 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.46      0.55       397\n",
      "           1       0.39      0.61      0.47       219\n",
      "\n",
      "    accuracy                           0.51       616\n",
      "   macro avg       0.53      0.54      0.51       616\n",
      "weighted avg       0.58      0.51      0.52       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emolex con TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tfidf_emolex(tr_txt, emolex_dict, emolex_dict_ind)\n",
    "bow_val = build_bow_tfidf_emolex(val_txt, emolex_dict, emolex_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183 214]\n",
      " [ 85 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.46      0.55       397\n",
      "           1       0.39      0.61      0.47       219\n",
      "\n",
      "    accuracy                           0.51       616\n",
      "   macro avg       0.53      0.54      0.51       616\n",
      "weighted avg       0.58      0.51      0.52       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emolex binario con normalizacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_binary_norm_emolex(tr_txt, emolex_dict, emolex_dict_ind)\n",
    "bow_val = build_bow_binary_norm_emolex(val_txt, emolex_dict, emolex_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259 138]\n",
      " [127  92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       397\n",
      "           1       0.40      0.42      0.41       219\n",
      "\n",
      "    accuracy                           0.57       616\n",
      "   macro avg       0.54      0.54      0.54       616\n",
      "weighted avg       0.57      0.57      0.57       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emolex TF con normalización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf_norm_emolex(tr_txt, emolex_dict, emolex_dict_ind)\n",
    "bow_val = build_bow_tf_norm_emolex(val_txt, emolex_dict, emolex_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259 138]\n",
      " [127  92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       397\n",
      "           1       0.40      0.42      0.41       219\n",
      "\n",
      "    accuracy                           0.57       616\n",
      "   macro avg       0.54      0.54      0.54       616\n",
      "weighted avg       0.57      0.57      0.57       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emolex TF-IDF con normalización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tfidf_norm_emolex(tr_txt, emolex_dict, emolex_dict_ind)\n",
    "bow_val = build_bow_tfidf_norm_emolex(val_txt, emolex_dict, emolex_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259 138]\n",
      " [127  92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       397\n",
      "           1       0.40      0.42      0.41       219\n",
      "\n",
      "    accuracy                           0.57       616\n",
      "   macro avg       0.54      0.54      0.54       616\n",
      "weighted avg       0.57      0.57      0.57       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesado  | F1-score | Accuracy\n",
      "_______/_\\________/_\\________\n",
      "Binary  |   0.48   |   0.52\n",
      "--------+----------+---------\n",
      "Binary  |   0.41   |   0.57\n",
      "normed  |          |\n",
      "--------+----------+---------\n",
      "TF      |   0.47   |   0.51\n",
      "--------+----------+---------\n",
      "TF      |   0.41   |   0.57\n",
      "normed  |          |\n",
      "--------+----------+---------\n",
      "TF-IDF  |   0.47   |   0.51\n",
      "--------+----------+---------\n",
      "TF-IDF  |   0.41   |   0.57\n",
      "normed  |          |\n"
     ]
    }
   ],
   "source": [
    "print('Pesado  | F1-score | Accuracy\\n_______/_\\________/_\\________')\n",
    "print('Binary  |   0.48   |   0.52\\n--------+----------+---------')\n",
    "print('Binary  |   0.41   |   0.57\\nnormed  |          |\\n--------+----------+---------')\n",
    "print('TF      |   0.47   |   0.51\\n--------+----------+---------')\n",
    "print('TF      |   0.41   |   0.57\\nnormed  |          |\\n--------+----------+---------')\n",
    "print('TF-IDF  |   0.47   |   0.51\\n--------+----------+---------')\n",
    "print('TF-IDF  |   0.41   |   0.57\\nnormed  |          |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que el desempleño de esta estrategia no es muy bueno. Ayuda un poco el normalizar los pesos pues logra un accuracy de 0.57, sin embargo, los f1-score son bajos lo cual nos habla que puede haber más errores que aciertos en los casos que se contemplan con recall o precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Recurso Línguistico de Emociones Mexicano\n",
    "\n",
    "## 3.1.1. Bolsa de emociones con el nuevo recurso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(path_corpus):\n",
    "    tr_txt = []\n",
    "    tr_y = []\n",
    "    tr_p = []\n",
    "    \n",
    "    with open(path_corpus, 'r', encoding='latin1') as f_corpus:\n",
    "        for word in f_corpus:\n",
    "            word = word.split()\n",
    "            tr_txt += [word[0]]\n",
    "            tr_p += [word[1]]\n",
    "            tr_y += [word[2]]\n",
    "            \n",
    "    return tr_txt, tr_y, tr_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel, sel_y, pfa = get_text_from_file('SEL.txt')\n",
    "sel = sel[1:]\n",
    "sel_y = sel_y[1:]\n",
    "pfa = pfa[1:]\n",
    "for i in range(len(pfa)):\n",
    "    pfa[i] = float(pfa[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_dict = {}\n",
    "sel_dict_pfa = {}\n",
    "for i in range(len(sel)):\n",
    "    word = sel[i]\n",
    "    sel_dict[word] = sel_y[i]\n",
    "    sel_dict_pfa[word] = pfa[i]\n",
    "    \n",
    "sel_dict_ind = {}\n",
    "count = 0\n",
    "for word in set(sel_y):\n",
    "    sel_dict_ind[word] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el esquema de pesado TF normalizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf_norm_emolex(tr_txt, sel_dict, sel_dict_ind)\n",
    "bow_val = build_bow_tf_norm_emolex(val_txt, sel_dict, sel_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348  49]\n",
      " [176  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.76       397\n",
      "           1       0.47      0.20      0.28       219\n",
      "\n",
      "    accuracy                           0.63       616\n",
      "   macro avg       0.57      0.54      0.52       616\n",
      "weighted avg       0.59      0.63      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con SEL se obtiene un mejor accuracy de 0.63, veamos ahora que pasa al incorporar la probabilidad.\n",
    "\n",
    "## 3.1.2. Incorporamos el factor de probabilidad de la afectividad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuevas funciones de la bolsa de emocines para incorporar dicha probabilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bow_binary_sel(tr_txt, emo_dict, dict_ind, dict_pfa):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado binario.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = dict_pfa[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tf_sel(tr_txt, emo_dict, dict_ind, dict_pfa):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento. \n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = fdist_doc[word]*dict_pfa[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tfidf_sel(tr_txt, emo_dict, dict_ind, dict_pfa):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento y penalizado por la frecuencia del término\n",
    "    en cada documento.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(emo_dict)), dtype=float)\n",
    "    idf = np.zeros(len(emo_dict), dtype=float)\n",
    "    \n",
    "    # Parte de TF\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]]  = fdist_doc[word]*dict_pfa[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Parte de IDF\n",
    "    N = len(tr_txt)\n",
    "    for word in emo_dict:\n",
    "        emo = emo_dict[word]\n",
    "        df = sum(bow[:, dict_ind[emo]] > 0)\n",
    "        if df == 0:\n",
    "            df = 1\n",
    "        idf[dict_ind[emo]] = np.log(N) - np.log(df)\n",
    "        \n",
    "    bow *= idf\n",
    "    return bow\n",
    "\n",
    "def build_bow_binary_norm_sel(tr_txt, emo_dict, dict_ind, dict_pfa):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado binario.\n",
    "    Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = dict_pfa[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tf_norm_sel(tr_txt, emo_dict, dict_ind, dict_pfa):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento. Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(dict_ind)), dtype=float)\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]] = fdist_doc[word]*dict_pfa[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "        \n",
    "    return bow\n",
    "\n",
    "def build_bow_tfidf_norm_sel(tr_txt, emo_dict, dict_ind, dict_pfa):\n",
    "    '''\n",
    "    Constructor de la bolsa de términos con un método de pesado por frecuencia\n",
    "    de los términos en cada documento y penalizado por la frecuencia del término\n",
    "    en cada documento. Además, normalizado con la norma L2.\n",
    "    '''\n",
    "    bow = np.zeros((len(tr_txt), len(emo_dict)), dtype=float)\n",
    "    idf = np.zeros(len(emo_dict), dtype=float)\n",
    "    \n",
    "    # Parte de TF\n",
    "    doc_count = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        for word in fdist_doc:\n",
    "            if word in emo_dict:\n",
    "                emo = emo_dict[word]\n",
    "                bow[doc_count, dict_ind[emo]]  = fdist_doc[word]*dict_pfa[word]\n",
    "        doc_count += 1\n",
    "        \n",
    "    # Parte de IDF\n",
    "    N = len(tr_txt)\n",
    "    for word in emo_dict:\n",
    "        emo = emo_dict[word]\n",
    "        df = sum(bow[:, dict_ind[emo]] > 0)\n",
    "        if df == 0:\n",
    "            df = 1\n",
    "        idf[dict_ind[emo]] = np.log(N) - np.log(df)\n",
    "        \n",
    "    bow *= idf\n",
    "    \n",
    "    # Normalización L2\n",
    "    for i in range(len(bow)):\n",
    "        sum_w = np.sqrt(bow[i]@bow[i])\n",
    "        if sum_w != 0:\n",
    "            bow[i] /= sum_w\n",
    "            \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_binary_sel(tr_txt, sel_dict, sel_dict_ind, sel_dict_pfa)\n",
    "bow_val = build_bow_binary_sel(val_txt, sel_dict, sel_dict_ind, sel_dict_pfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348  49]\n",
      " [175  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       397\n",
      "           1       0.47      0.20      0.28       219\n",
      "\n",
      "    accuracy                           0.64       616\n",
      "   macro avg       0.57      0.54      0.52       616\n",
      "weighted avg       0.60      0.64      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf_sel(tr_txt, sel_dict, sel_dict_ind, sel_dict_pfa)\n",
    "bow_val = build_bow_tf_sel(val_txt, sel_dict, sel_dict_ind, sel_dict_pfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348  49]\n",
      " [175  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       397\n",
      "           1       0.47      0.20      0.28       219\n",
      "\n",
      "    accuracy                           0.64       616\n",
      "   macro avg       0.57      0.54      0.52       616\n",
      "weighted avg       0.60      0.64      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tfidf_sel(tr_txt, sel_dict, sel_dict_ind, sel_dict_pfa)\n",
    "bow_val = build_bow_tfidf_sel(val_txt, sel_dict, sel_dict_ind, sel_dict_pfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[351  46]\n",
      " [178  41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.76       397\n",
      "           1       0.47      0.19      0.27       219\n",
      "\n",
      "    accuracy                           0.64       616\n",
      "   macro avg       0.57      0.54      0.51       616\n",
      "weighted avg       0.60      0.64      0.58       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_binary_norm_sel(tr_txt, sel_dict, sel_dict_ind, sel_dict_pfa)\n",
    "bow_val = build_bow_binary_norm_sel(val_txt, sel_dict, sel_dict_ind, sel_dict_pfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347  50]\n",
      " [174  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76       397\n",
      "           1       0.47      0.21      0.29       219\n",
      "\n",
      "    accuracy                           0.64       616\n",
      "   macro avg       0.57      0.54      0.52       616\n",
      "weighted avg       0.60      0.64      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tf_norm_sel(tr_txt, sel_dict, sel_dict_ind, sel_dict_pfa)\n",
    "bow_val = build_bow_tf_norm_sel(val_txt, sel_dict, sel_dict_ind, sel_dict_pfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347  50]\n",
      " [175  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.76       397\n",
      "           1       0.47      0.20      0.28       219\n",
      "\n",
      "    accuracy                           0.63       616\n",
      "   macro avg       0.57      0.54      0.52       616\n",
      "weighted avg       0.59      0.63      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tr = build_bow_tfidf_norm_sel(tr_txt, sel_dict, sel_dict_ind, sel_dict_pfa)\n",
    "bow_val = build_bow_tfidf_norm_sel(val_txt, sel_dict, sel_dict_ind, sel_dict_pfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(class_weight='balanced'), n_jobs=8,\n",
       "             param_grid={'C': [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(bow_tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347  50]\n",
      " [176  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75       397\n",
      "           1       0.46      0.20      0.28       219\n",
      "\n",
      "    accuracy                           0.63       616\n",
      "   macro avg       0.56      0.54      0.51       616\n",
      "weighted avg       0.59      0.63      0.58       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(bow_val)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesado  | F1-score | Accuracy\n",
      "_______/_\\________/_\\________\n",
      "Binary  |   0.28   |   0.64\n",
      "--------+----------+---------\n",
      "Binary  |   0.29   |   0.64\n",
      "normed  |          |\n",
      "--------+----------+---------\n",
      "TF      |   0.28   |   0.64\n",
      "--------+----------+---------\n",
      "TF      |   0.28   |   0.63\n",
      "normed  |          |\n",
      "--------+----------+---------\n",
      "TF-IDF  |   0.27   |   0.64\n",
      "--------+----------+---------\n",
      "TF-IDF  |   0.28   |   0.63\n",
      "normed  |          |\n"
     ]
    }
   ],
   "source": [
    "print('Pesado  | F1-score | Accuracy\\n_______/_\\________/_\\________')\n",
    "print('Binary  |   0.28   |   0.64\\n--------+----------+---------')\n",
    "print('Binary  |   0.29   |   0.64\\nnormed  |          |\\n--------+----------+---------')\n",
    "print('TF      |   0.28   |   0.64\\n--------+----------+---------')\n",
    "print('TF      |   0.28   |   0.63\\nnormed  |          |\\n--------+----------+---------')\n",
    "print('TF-IDF  |   0.27   |   0.64\\n--------+----------+---------')\n",
    "print('TF-IDF  |   0.28   |   0.63\\nnormed  |          |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que dicha incorporacion de probabilidad mejora a 0.64 el accuracy que se tenía, ya sea para cualquier esquema de pesado. Para la normalización, se mejora el f1-Score de la clase agresivo para el binario y empeora el accuracy para los demás esquemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Comentario sobre la estrategia de incorporación de la PFA\n",
    "\n",
    "La idea que se realizó fue incorporar la PFA en la bolsa de emociones de la siguiente manera:\n",
    "* Para el pesado binario, se cambio el 1 por la PFA de la emoción que la palabra transmite.\n",
    "* Para el pesado TF, se multiplica la frecuencia por la PFA de la emoción que la palabra transmite.\n",
    "* Para el pesado TF-IDF, solamente se incormpora en la parte TF como se menciona arriba.\n",
    "\n",
    "Me pareció la más adecuada debido a que cada twitt tendrá una probabilidad de los sentimientos dependiendo de la palabra que aparece en él."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ¿Le podemos ganar a BoW con Bigramas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Realizamos concatenaciones de todo lo realizado anteriormente:\n",
    "\n",
    "Para no combinar todas las opciones posibles a lo «loco», solo combianremos los casos que los algoritmos tuvieron mejor desempeño en las evaluaciones anteriores.\n",
    "\n",
    "Creamos las BoW con mejor desempeño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de términos\n",
    "bow_tr = build_bow_tf(tr_txt, V, dict_ind)\n",
    "bow_val = build_bow_tf(val_txt, V, dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de bigramas\n",
    "bow_tr_bi = build_bobg_tf_norm(tr_txt, V_bigr, dict_ind_bigr)\n",
    "bow_val_bi = build_bobg_tf_norm(val_txt, V_bigr, dict_ind_bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de emociones con Emolex\n",
    "bow_tr_emx = build_bow_tf_norm_emolex(tr_txt, emolex_dict, emolex_dict_ind)\n",
    "bow_val_emx = build_bow_tf_norm_emolex(val_txt, emolex_dict, emolex_dict_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de emociones con SEL\n",
    "bow_tr_sel = build_bow_tf_norm_sel(tr_txt, sel_dict, sel_dict_ind, sel_dict_pfa)\n",
    "bow_val_sel = build_bow_tf_norm_sel(val_txt, sel_dict, sel_dict_ind, sel_dict_pfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclamos BoW con BoBigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr_con = np.concatenate((bow_tr, bow_tr_bi), axis=1)\n",
    "bow_val_con = np.concatenate((bow_val, bow_val_bi), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332  65]\n",
      " [ 52 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       397\n",
      "           1       0.72      0.76      0.74       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.80      0.80       616\n",
      "weighted avg       0.81      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclamos BoW con BoE Emolex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr_con = np.concatenate((bow_tr, bow_tr_emx), axis=1)\n",
    "bow_val_con = np.concatenate((bow_val, bow_val_emx), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[334  63]\n",
      " [ 51 168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       397\n",
      "           1       0.73      0.77      0.75       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.80      0.80      0.80       616\n",
      "weighted avg       0.82      0.81      0.82       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclamos BoW con BoE SEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr_con = np.concatenate((bow_tr, bow_tr_sel), axis=1)\n",
    "bow_val_con = np.concatenate((bow_val, bow_val_sel), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333  64]\n",
      " [ 50 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       397\n",
      "           1       0.73      0.77      0.75       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.80      0.81      0.80       616\n",
      "weighted avg       0.82      0.81      0.82       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahorita todos han dado los mismos resultados, ahora tratemos de agregar 2:\n",
    "\n",
    "Mezclamos BoW con BoBigrams y BoE Emolex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr_con = np.concatenate((bow_tr, bow_tr_bi, bow_tr_emx), axis=1)\n",
    "bow_val_con = np.concatenate((bow_val, bow_val_bi, bow_val_emx), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[331  66]\n",
      " [ 53 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       397\n",
      "           1       0.72      0.76      0.74       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.80      0.79       616\n",
      "weighted avg       0.81      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclamos BoW con BoBigrams y BoE SEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr_con = np.concatenate((bow_tr, bow_tr_bi, bow_tr_sel), axis=1)\n",
    "bow_val_con = np.concatenate((bow_val, bow_val_bi, bow_val_sel), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332  65]\n",
      " [ 53 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       397\n",
      "           1       0.72      0.76      0.74       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.80      0.79       616\n",
      "weighted avg       0.81      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclamos BoW con BoE emolex y BoE SEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr_con = np.concatenate((bow_tr, bow_tr_emx, bow_tr_sel), axis=1)\n",
    "bow_val_con = np.concatenate((bow_val, bow_val_emx, bow_val_sel), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[334  63]\n",
      " [ 52 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       397\n",
      "           1       0.73      0.76      0.74       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.80      0.80      0.80       616\n",
      "weighted avg       0.82      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, no tenemos resultados notables a favor. Por último intentemos las 4 características concatenadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos\n",
    "bow_tr_con = np.concatenate((bow_tr, bow_tr_bi, bow_tr_emx, bow_tr_sel), axis=1)\n",
    "bow_val_con = np.concatenate((bow_val, bow_val_bi, bow_val_emx, bow_val_sel), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[330  67]\n",
      " [ 53 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       397\n",
      "           1       0.71      0.76      0.73       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.79      0.79       616\n",
      "weighted avg       0.81      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolsa original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[334  63]\n",
      " [ 50 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       397\n",
      "           1       0.73      0.77      0.75       219\n",
      "\n",
      "    accuracy                           0.82       616\n",
      "   macro avg       0.80      0.81      0.80       616\n",
      "weighted avg       0.82      0.82      0.82       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bow_tr_con = bow_tr\n",
    "bow_val_con = bow_val\n",
    "grid.fit(bow_tr_con, tr_y)\n",
    "y_pred = grid.predict(bow_val_con)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(metrics.classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinación    | F1-score | Accuracy\n",
      "______________/_\\________/_\\________\n",
      "BoW            |   0.75   |   0.82\n",
      "---------------+----------+---------\n",
      "Bow+BoBigr     |   0.74   |   0.81\n",
      "---------------+----------+---------\n",
      "BoW+BoE emx    |   0.75   |   0.81\n",
      "---------------+----------+---------\n",
      "BoW+BoE SEL    |   0.75   |   0.81\n",
      "---------------+----------+---------\n",
      "Bow+BoB+BoEmx  |   0.74   |   0.81\n",
      "---------------+----------+---------\n",
      "Bow+BoB+BoSEL  |   0.74   |   0.81\n",
      "---------------+----------+---------\n",
      "Bow+BoEmx+BoSEL|   0.74   |   0.81\n",
      "---------------+----------+---------\n",
      "Bow+ All       |   0.73   |   0.81\n"
     ]
    }
   ],
   "source": [
    "print('Combinación    | F1-score | Accuracy\\n______________/_\\________/_\\________')\n",
    "print('BoW            |   0.75   |   0.82\\n---------------+----------+---------')\n",
    "print('Bow+BoBigr     |   0.74   |   0.81\\n---------------+----------+---------')\n",
    "print('BoW+BoE emx    |   0.75   |   0.81\\n---------------+----------+---------')\n",
    "print('BoW+BoE SEL    |   0.75   |   0.81\\n---------------+----------+---------')\n",
    "print('Bow+BoB+BoEmx  |   0.74   |   0.81\\n---------------+----------+---------')\n",
    "print('Bow+BoB+BoSEL  |   0.74   |   0.81\\n---------------+----------+---------')\n",
    "print('Bow+BoEmx+BoSEL|   0.74   |   0.81\\n---------------+----------+---------')\n",
    "print('Bow+ All       |   0.73   |   0.81')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tarea se experimenta sobre las posibles alternativas que se pueden tomar al pesar cada término de los documentos. Se logra notar que muchas veces es mejor normalizar las bolsas de términos para mejorar el desempeño. Se probaron además distintas variaciones en las bolsas para ver si podían servir para mejorar la bolsa de términos original. De ellos fue una bolsa de bigramas, una bolsa de emociones y una bolsa de emociones con probabilidad. Concatenando a la bolsa original **no** se logra mejorar el F1-score ni el accuraccy en ninguna combinación. El f1-score más cercano es el de BoW+BoE SEL o BoW+BoE Emx sin embargo clasifican mal 1 elemento más de la validación que la bolsa original.\n",
    "\n",
    "Como comentario, me sorprendió que al principio el TF-IDF no hiciera tan buen trabajo y en varias ocasiones peor. También fue sorprendente todo lo que se agregó y ni así se pudo superar a la bolsa original. Una recomendación futura es que podríamos agregar un feature bueno que al evaluarlo por si solo tuviera buen desempeño puesto que todos los features nuevos que agregamos, no pasaban del .63 en accuracy, y por tanto era muy improbable lograr observar una mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
